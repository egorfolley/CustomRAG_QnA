{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5443e62b",
   "metadata": {},
   "source": [
    "# Playground for custom RAG system\n",
    "____\n",
    "## Ingestion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d621b063",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import PyPDF2\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7df6c71f",
   "metadata": {},
   "outputs": [],
   "source": [
    "CHUNK_SIZE = 80\n",
    "CHUNK_OVERLAP = 30\n",
    "MISTRAL_API_KEY = os.getenv(\"MISTRAL_API_KEY\")\n",
    "\n",
    "if not MISTRAL_API_KEY:\n",
    "    raise ValueError(\"MISTRAL_API_KEY not found in environment variables\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ea0d8f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_from_pdf(pdf_file):\n",
    "    \"\"\"Extract text from PDF file\"\"\"\n",
    "    reader = PyPDF2.PdfReader(pdf_file)\n",
    "    text = \"\"\n",
    "    for page in reader.pages:\n",
    "        text += page.extract_text()\n",
    "    \n",
    "    return text\n",
    "\n",
    "\n",
    "def chunk_text(text, chunk_size=CHUNK_SIZE, overlap=CHUNK_OVERLAP):\n",
    "    \"\"\"Split text into overlapping chunks (simple word-based chunking)\"\"\"\n",
    "    words = text.split()\n",
    "    chunks = []\n",
    "    \n",
    "    for i in range(0, len(words), chunk_size - overlap):\n",
    "        chunk = ' '.join(words[i:i + chunk_size])\n",
    "        chunks.append(chunk)\n",
    "    \n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e4535755",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_file = \"data/test/Custom_RAG_Test_Document.pdf\"\n",
    "if not pdf_file.endswith('.pdf'):\n",
    "    raise ValueError(\"File must be a PDF\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b89f6da3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Custom RAG Test Document\n",
      "1. Company Overview\n",
      "Acme AI is a fictional enterprise software company specializing in AI agent deployment platforms\n",
      "for mid-sized businesses. The company was founded in 2021 and is headquartered in New York.\n",
      "2. Financial Summary (2025)\n",
      "Revenue: $18 million. Gross Margin: 72%. Net Income: -$2.4 million. Customer Growth Rate: 38%\n",
      "year-over-year.\n",
      "3. Competitive Landscape\n",
      "Primary competitors include StackAI, Credal, and Glean. Acme AI differentiates itself through rapid\n",
      "deployment cycles and strong enterprise security compliance.\n",
      "4. Macro Environment Context\n",
      "In 2025, tightening credit conditions and elevated interest rates impacted enterprise software\n",
      "spending. However, AI infrastructure investments continued due to productivity gains and\n",
      "automation trends.\n",
      "5. Risk Factors\n",
      "Key risks include increased competition, dependency on venture funding, and potential slowdown in\n",
      "SaaS budgets if macroeconomic conditions deteriorate.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "text = extract_text_from_pdf(pdf_file)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8556e411",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created 3 chunks\n"
     ]
    }
   ],
   "source": [
    "chunk_texts = chunk_text(text)\n",
    "print(f\"Created {len(chunk_texts)} chunks\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e478e407",
   "metadata": {},
   "source": [
    "### Creating embeddings (Mistral)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "fa1f14d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mistralai.client import MistralClient\n",
    "from app.config import MISTRAL_API_KEY, CHUNK_SIZE, CHUNK_OVERLAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "4fb65b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = MistralClient(api_key=MISTRAL_API_KEY)\n",
    "\n",
    "# Global storage (in-memory)\n",
    "chunks = []\n",
    "embeddings = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "dfecbb0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def embed_chunks(text_chunks):\n",
    "    \"\"\"Get embeddings from Mistral API\"\"\"\n",
    "    response = client.embeddings(\n",
    "            model=\"mistral-embed\",\n",
    "            input=text_chunks\n",
    "        )\n",
    "    data = response.data\n",
    "\n",
    "    return [item.embedding for item in response.data]\n",
    "\n",
    "# Testing full ingetion pipeline\n",
    "def ingest_pdf(pdf_file):\n",
    "    \"\"\"Main ingestion pipeline\"\"\"\n",
    "        \n",
    "    # Extract text\n",
    "    text = extract_text_from_pdf(pdf_file)\n",
    "    print(f\"Extracted text length: {len(text)} characters\")\n",
    "    \n",
    "    # Chunk text\n",
    "    new_text_chunks = chunk_text(text)\n",
    "    print(f\"Created {len(new_text_chunks)} chunks\")\n",
    "    \n",
    "    # Get embeddings\n",
    "    new_embeddings = embed_chunks(new_text_chunks)\n",
    "    print(f\"Generated embeddings for {len(new_embeddings)} chunks\")\n",
    "    \n",
    "    # Store\n",
    "    chunks.extend(new_text_chunks)\n",
    "    embeddings.extend(new_embeddings)\n",
    "    \n",
    "    return len(new_text_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "6e37d387",
   "metadata": {},
   "outputs": [],
   "source": [
    "# embed_chunks = embed_chunks(chunk_texts)\n",
    "# print(f\"Generated embeddings for {len(embed_chunks)} chunks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "e9e2c4c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted text length: 958 characters\n",
      "Created 3 chunks\n",
      "Generated embeddings for 3 chunks\n",
      "Ingested 3 chunks from PDF\n"
     ]
    }
   ],
   "source": [
    "num_chunks = ingest_pdf(pdf_file)\n",
    "print(f\"Ingested {num_chunks} chunks from PDF\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "84b152c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Len of embeddings: 3\n"
     ]
    }
   ],
   "source": [
    "print(f\"Len of embeddings: {len(embeddings)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e33e52c7",
   "metadata": {},
   "source": [
    "____\n",
    "### Query processing\n",
    "____"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a4810c96",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from app.config import MISTRAL_API_KEY, SIMILARITY_THRESHOLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "f733383b",
   "metadata": {},
   "outputs": [],
   "source": [
    "SIMILARITY_THRESHOLD = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "54d766a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def semantic_search(query, top_k=5):\n",
    "    \"\"\"Semantic search using embeddings\"\"\"\n",
    "    if not embeddings:\n",
    "        return []\n",
    "    \n",
    "    # Get query embedding\n",
    "    query_embedding = client.embeddings(\n",
    "        model=\"mistral-embed\",\n",
    "        input=[query]\n",
    "    ).data[0].embedding\n",
    "    \n",
    "    # Calculate cosine similarity\n",
    "    query_emb_array = np.array(query_embedding).reshape(1, -1)\n",
    "    chunk_emb_array = np.array(embeddings)\n",
    "    \n",
    "    similarities = cosine_similarity(query_emb_array, chunk_emb_array)[0]\n",
    "    \n",
    "    # Get top k indices\n",
    "    top_indices = np.argsort(similarities)[-top_k:][::-1]\n",
    "    \n",
    "    results = [\n",
    "        {\n",
    "            \"chunk\": chunks[i],\n",
    "            \"score\": float(similarities[i]),\n",
    "            \"index\": int(i)\n",
    "        }\n",
    "        for i in top_indices\n",
    "    ]\n",
    "    \n",
    "    return results\n",
    "\n",
    "\n",
    "def keyword_search(query, top_k=5):\n",
    "    \"\"\"Keyword search using TF-IDF\"\"\"\n",
    "    if not chunks:\n",
    "        return []\n",
    "    \n",
    "    # Create TF-IDF vectorizer\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    tfidf_matrix = vectorizer.fit_transform(chunks + [query])\n",
    "    \n",
    "    # Get query vector (last one)\n",
    "    query_vector = tfidf_matrix[-1:]\n",
    "    chunk_vectors = tfidf_matrix[:-1]\n",
    "    \n",
    "    # Calculate similarity\n",
    "    similarities = cosine_similarity(query_vector, chunk_vectors)[0]\n",
    "    \n",
    "    # Get top k indices\n",
    "    top_indices = np.argsort(similarities)[-top_k:][::-1]\n",
    "    \n",
    "    results = [\n",
    "        {\n",
    "            \"chunk\": chunks[i],\n",
    "            \"score\": float(similarities[i]),\n",
    "            \"index\": int(i)\n",
    "        }\n",
    "        for i in top_indices\n",
    "    ]\n",
    "    \n",
    "    return results\n",
    "\n",
    "\n",
    "def hybrid_search(query, semantic_weight=0.25, keyword_weight=0.3, top_k=5):\n",
    "    \"\"\"Combine semantic and keyword search\"\"\"\n",
    "    semantic_results = semantic_search(query, top_k=top_k * 2)\n",
    "    keyword_results = keyword_search(query, top_k=top_k * 2)\n",
    "    \n",
    "    # Combine scores\n",
    "    combined_scores = {}\n",
    "    \n",
    "    for result in semantic_results:\n",
    "        idx = result[\"index\"]\n",
    "        combined_scores[idx] = semantic_weight * result[\"score\"]\n",
    "    \n",
    "    for result in keyword_results:\n",
    "        idx = result[\"index\"]\n",
    "        if idx in combined_scores:\n",
    "            combined_scores[idx] += keyword_weight * result[\"score\"]\n",
    "        else:\n",
    "            combined_scores[idx] = keyword_weight * result[\"score\"]\n",
    "    \n",
    "    # Sort by combined score\n",
    "    sorted_indices = sorted(combined_scores.items(), key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    # Get top k unique chunks\n",
    "    final_results = [\n",
    "        {\n",
    "            \"chunk\": chunks[idx],\n",
    "            \"score\": score,\n",
    "            \"index\": idx\n",
    "        }\n",
    "        for idx, score in sorted_indices[:top_k]\n",
    "    ]\n",
    "    \n",
    "    return final_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "4ccebb5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Semantic Search Results: [{'chunk': 'Custom RAG Test Document 1. Company Overview Acme AI is a fictional enterprise software company specializing in AI agent deployment platforms for mid-sized businesses. The company was founded in 2021 and is headquartered in New York. 2. Financial Summary (2025) Revenue: $18 million. Gross Margin: 72%. Net Income: -$2.4 million. Customer Growth Rate: 38% year-over-year. 3. Competitive Landscape Primary competitors include StackAI, Credal, and Glean. Acme AI differentiates itself through rapid deployment cycles and strong enterprise security compliance. 4. Macro', 'score': 0.8227605339500232, 'index': 0}, {'chunk': 'Customer Growth Rate: 38% year-over-year. 3. Competitive Landscape Primary competitors include StackAI, Credal, and Glean. Acme AI differentiates itself through rapid deployment cycles and strong enterprise security compliance. 4. Macro Environment Context In 2025, tightening credit conditions and elevated interest rates impacted enterprise software spending. However, AI infrastructure investments continued due to productivity gains and automation trends. 5. Risk Factors Key risks include increased competition, dependency on venture funding, and potential slowdown in SaaS budgets if macroeconomic conditions deteriorate.', 'score': 0.809562923794385, 'index': 1}, {'chunk': 'due to productivity gains and automation trends. 5. Risk Factors Key risks include increased competition, dependency on venture funding, and potential slowdown in SaaS budgets if macroeconomic conditions deteriorate.', 'score': 0.6955305813253201, 'index': 2}]\n",
      "Keyword Search Results: [{'chunk': 'Custom RAG Test Document 1. Company Overview Acme AI is a fictional enterprise software company specializing in AI agent deployment platforms for mid-sized businesses. The company was founded in 2021 and is headquartered in New York. 2. Financial Summary (2025) Revenue: $18 million. Gross Margin: 72%. Net Income: -$2.4 million. Customer Growth Rate: 38% year-over-year. 3. Competitive Landscape Primary competitors include StackAI, Credal, and Glean. Acme AI differentiates itself through rapid deployment cycles and strong enterprise security compliance. 4. Macro', 'score': 0.1160321847114242, 'index': 0}, {'chunk': 'Customer Growth Rate: 38% year-over-year. 3. Competitive Landscape Primary competitors include StackAI, Credal, and Glean. Acme AI differentiates itself through rapid deployment cycles and strong enterprise security compliance. 4. Macro Environment Context In 2025, tightening credit conditions and elevated interest rates impacted enterprise software spending. However, AI infrastructure investments continued due to productivity gains and automation trends. 5. Risk Factors Key risks include increased competition, dependency on venture funding, and potential slowdown in SaaS budgets if macroeconomic conditions deteriorate.', 'score': 0.07752477353509417, 'index': 1}, {'chunk': 'due to productivity gains and automation trends. 5. Risk Factors Key risks include increased competition, dependency on venture funding, and potential slowdown in SaaS budgets if macroeconomic conditions deteriorate.', 'score': 0.0, 'index': 2}]\n"
     ]
    }
   ],
   "source": [
    "query = \"What are Acme AI' revenues?\"\n",
    "\n",
    "semantic_search_results = semantic_search(query)\n",
    "print(f\"Semantic Search Results: {semantic_search_results}\")\n",
    "\n",
    "keyword_search_results = keyword_search(query)\n",
    "print(f\"Keyword Search Results: {keyword_search_results}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "db90035a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hybrid Search Results: [{'chunk': 'Custom RAG Test Document 1. Company Overview Acme AI is a fictional enterprise software company specializing in AI agent deployment platforms for mid-sized businesses. The company was founded in 2021 and is headquartered in New York. 2. Financial Summary (2025) Revenue: $18 million. Gross Margin: 72%. Net Income: -$2.4 million. Customer Growth Rate: 38% year-over-year. 3. Competitive Landscape Primary competitors include StackAI, Credal, and Glean. Acme AI differentiates itself through rapid deployment cycles and strong enterprise security compliance. 4. Macro', 'score': 0.24049978890093307, 'index': 0}, {'chunk': 'Customer Growth Rate: 38% year-over-year. 3. Competitive Landscape Primary competitors include StackAI, Credal, and Glean. Acme AI differentiates itself through rapid deployment cycles and strong enterprise security compliance. 4. Macro Environment Context In 2025, tightening credit conditions and elevated interest rates impacted enterprise software spending. However, AI infrastructure investments continued due to productivity gains and automation trends. 5. Risk Factors Key risks include increased competition, dependency on venture funding, and potential slowdown in SaaS budgets if macroeconomic conditions deteriorate.', 'score': 0.2256481630091245, 'index': 1}, {'chunk': 'due to productivity gains and automation trends. 5. Risk Factors Key risks include increased competition, dependency on venture funding, and potential slowdown in SaaS budgets if macroeconomic conditions deteriorate.', 'score': 0.17388264533133002, 'index': 2}]\n"
     ]
    }
   ],
   "source": [
    "hybrid_search_results = hybrid_search(query)\n",
    "print(f\"Hybrid Search Results: {hybrid_search_results}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97e9b929",
   "metadata": {},
   "source": [
    "____\n",
    "### Retieval \n",
    "____"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5984fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "dcabc502",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_intent(query):\n",
    "    \"\"\"Simple intent detection - check if query needs search\"\"\"\n",
    "    greetings = [\"hello\", \"hi\", \"hey\", \"thanks\", \"thank you\", \"bye\"]\n",
    "    query_lower = query.lower().strip()\n",
    "    \n",
    "    # Don't search for greetings\n",
    "    if any(greeting in query_lower for greeting in greetings):\n",
    "        return False\n",
    "    \n",
    "    # Search for actual questions\n",
    "    return len(query_lower.split()) > 2\n",
    "\n",
    "\n",
    "def transform_query(query):\n",
    "    \"\"\"Simple query transformation\"\"\"\n",
    "    # Basic cleaning\n",
    "    query = query.strip().lower()\n",
    "    \n",
    "    # Expand common abbreviations (optional)\n",
    "    expansions = {\n",
    "        \"q&a\": \"question and answer\",\n",
    "        \"info\": \"information\",\n",
    "    }\n",
    "    \n",
    "    for abbr, full in expansions.items():\n",
    "        query = query.replace(abbr, full)\n",
    "    \n",
    "    return query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "9049fa3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_answer(query, retrieved_chunks):\n",
    "    \"\"\"Generate answer using Mistral LLM\"\"\"\n",
    "\n",
    "    if retrieved_chunks:\n",
    "        for i, chunk in enumerate(retrieved_chunks[:3]):\n",
    "            print(f\"Chunk {i+1} score: {chunk['score']:.4f}\")\n",
    "    else:\n",
    "        print(\"No chunks retrieved!\")\n",
    "    \n",
    "    # Check similarity threshold\n",
    "    if not retrieved_chunks or retrieved_chunks[0][\"score\"] < SIMILARITY_THRESHOLD:\n",
    "        print(f\"Top score {retrieved_chunks[0]['score'] if retrieved_chunks else 0:.2f} < threshold {SIMILARITY_THRESHOLD}\")\n",
    "        \n",
    "        return {\n",
    "            \"answer\": \"Insufficient evidence in the knowledge base to answer this question confidently.\",\n",
    "            \"chunks\": retrieved_chunks[:3] if retrieved_chunks else [],  # Return chunks anyway for debugging\n",
    "            \"reasoning\": f\"Top chunk similarity ({retrieved_chunks[0]['score'] if retrieved_chunks else 0:.2f}) is below threshold ({SIMILARITY_THRESHOLD})\"\n",
    "        }\n",
    "    \n",
    "    # Build context from top chunks\n",
    "    context = \"\\n\\n\".join([\n",
    "        f\"[Chunk {i+1}]: {chunk['chunk']}\"\n",
    "        for i, chunk in enumerate(retrieved_chunks[:3])\n",
    "    ])\n",
    "    \n",
    "    # Build prompt\n",
    "    prompt = f\"\"\"Based on the following document excerpts, answer the user's question.\n",
    "\n",
    "        Context:\n",
    "        {context}\n",
    "\n",
    "        Question: {query}\n",
    "\n",
    "        Instructions:\n",
    "        - Provide a clear, concise answer based ONLY on the context provided\n",
    "        - Cite which chunk(s) support your answer (e.g., \"According to Chunk 1...\")\n",
    "        - If the context doesn't contain enough information, say so\n",
    "        - Do not make up information not present in the context\n",
    "\n",
    "        Answer:\n",
    "    \"\"\"\n",
    "    \n",
    "    # Call Mistral API\n",
    "    response = client.chat(\n",
    "        model=\"mistral-small-latest\",\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "    )\n",
    "    \n",
    "    answer = response.choices[0].message.content\n",
    "    \n",
    "    return {\n",
    "        \"answer\": answer,\n",
    "        \"chunks\": retrieved_chunks[:3],\n",
    "        \"threshold_passed\": True\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "09e39cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"What are the revenues of Acme AI?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "15ef3c59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 1 score: 0.2243\n",
      "Chunk 2 score: 0.1977\n",
      "Chunk 3 score: 0.1367\n"
     ]
    }
   ],
   "source": [
    "# Intent detection\n",
    "needs_search = detect_intent(query)\n",
    "if not needs_search:\n",
    "    print(\"No search needed, returning default response.\")\n",
    "\n",
    "# Transform query\n",
    "processed_query = transform_query(query)\n",
    "\n",
    "# Hybrid search\n",
    "retrieved_chunks = hybrid_search(processed_query)\n",
    "\n",
    "# Generate answer\n",
    "result = generate_answer(query, retrieved_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "07729336",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'answer': \"According to Chunk 1, Acme AI's revenue in 2025 is $18 million.\",\n",
       " 'chunks': [{'chunk': 'Custom RAG Test Document 1. Company Overview Acme AI is a fictional enterprise software company specializing in AI agent deployment platforms for mid-sized businesses. The company was founded in 2021 and is headquartered in New York. 2. Financial Summary (2025) Revenue: $18 million. Gross Margin: 72%. Net Income: -$2.4 million. Customer Growth Rate: 38% year-over-year. 3. Competitive Landscape Primary competitors include StackAI, Credal, and Glean. Acme AI differentiates itself through rapid deployment cycles and strong enterprise security compliance. 4. Macro',\n",
       "   'score': 0.2242576753076676,\n",
       "   'index': 0},\n",
       "  {'chunk': 'Customer Growth Rate: 38% year-over-year. 3. Competitive Landscape Primary competitors include StackAI, Credal, and Glean. Acme AI differentiates itself through rapid deployment cycles and strong enterprise security compliance. 4. Macro Environment Context In 2025, tightening credit conditions and elevated interest rates impacted enterprise software spending. However, AI infrastructure investments continued due to productivity gains and automation trends. 5. Risk Factors Key risks include increased competition, dependency on venture funding, and potential slowdown in SaaS budgets if macroeconomic conditions deteriorate.',\n",
       "   'score': 0.19766203491727036,\n",
       "   'index': 1},\n",
       "  {'chunk': 'due to productivity gains and automation trends. 5. Risk Factors Key risks include increased competition, dependency on venture funding, and potential slowdown in SaaS budgets if macroeconomic conditions deteriorate.',\n",
       "   'score': 0.1366858431812959,\n",
       "   'index': 2}],\n",
       " 'threshold_passed': True}"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
